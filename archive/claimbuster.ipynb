{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/codespace/.python/current/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /home/codespace/.python/current/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /home/codespace/.python/current/lib/python3.12/site-packages (from nltk) (4.66.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: contractions in /home/codespace/.python/current/lib/python3.12/site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /home/codespace/.python/current/lib/python3.12/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in /home/codespace/.python/current/lib/python3.12/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in /home/codespace/.python/current/lib/python3.12/site-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /home/codespace/.python/current/lib/python3.12/site-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: chardet in /home/codespace/.python/current/lib/python3.12/site-packages (5.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in /home/codespace/.python/current/lib/python3.12/site-packages (4.66.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /home/codespace/.python/current/lib/python3.12/site-packages (4.44.2)\n",
      "Requirement already satisfied: accelerate in /home/codespace/.python/current/lib/python3.12/site-packages (0.34.2)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.12/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from accelerate) (2.4.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (73.0.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/codespace/.python/current/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.6.68)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/codespace/.local/lib/python3.12/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /home/codespace/.python/current/lib/python3.12/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch) (73.0.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/codespace/.python/current/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.68)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/codespace/.local/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "%pip install contractions\n",
    "%pip install transformers\n",
    "%pip install chardet\n",
    "%pip install tqdm\n",
    "%pip install --upgrade transformers accelerate\n",
    "%pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaModel\n",
    "# from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# from transformers import DistilBertTokenizer, DistilBertModel, AdamW\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import chardet\n",
    "import torch.nn as nn\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import json\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2829, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/workspaces/misinformation/labeled_data_opinion_true.csv', encoding='utf-8')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ClaimBuster is designed to detect factual claims in textual data. It provides a factual claim score (ranging from 0 to 1) that reflects how much a piece of text resembles a factual claim, with higher scores indicating a stronger factual claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n",
      "Error occurred: 0\n"
     ]
    }
   ],
   "source": [
    "api_key = \"1d4a3eb3686441c0924adf0165146cb4\"\n",
    "\n",
    "def get_claimbuster_score(text):\n",
    "    try:\n",
    "        # Define the endpoint with the claim as part of it\n",
    "        api_endpoint = f\"https://idir.uta.edu/claimbuster/api/v2/score/text/{text}\"\n",
    "        request_headers = {\"x-api-key\": api_key}\n",
    "\n",
    "        response = requests.get(url=api_endpoint, headers=request_headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result['results'][0]['score']  \n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            return None  \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return None \n",
    "\n",
    "data['claimbuster_score'] = data['text'].apply(get_claimbuster_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>author.userName</th>\n",
       "      <th>misinformation</th>\n",
       "      <th>stance</th>\n",
       "      <th>isUSRelated</th>\n",
       "      <th>notes</th>\n",
       "      <th>opinion_label</th>\n",
       "      <th>true_label</th>\n",
       "      <th>claimbuster_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T2</td>\n",
       "      <td>1459086</td>\n",
       "      <td>Unconfirmed reports claiming to originate from...</td>\n",
       "      <td>_HenryBolton</td>\n",
       "      <td>O</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.505682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T4</td>\n",
       "      <td>198836</td>\n",
       "      <td>Brexit is not the reason for the insecurity of...</td>\n",
       "      <td>_HenryBolton</td>\n",
       "      <td>O</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T2</td>\n",
       "      <td>1131342</td>\n",
       "      <td>I’ll be on @talkRADIO in around 5-10 (3:20pm i...</td>\n",
       "      <td>_HenryBolton</td>\n",
       "      <td>O</td>\n",
       "      <td>P</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.418709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T2</td>\n",
       "      <td>1345479</td>\n",
       "      <td>The judge hearing Djokovic’s deportation appea...</td>\n",
       "      <td>_HenryBolton</td>\n",
       "      <td>T</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.605284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T2</td>\n",
       "      <td>1116059</td>\n",
       "      <td>An order to a Border Force vessel to turn back...</td>\n",
       "      <td>_HenryBolton</td>\n",
       "      <td>O</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.530550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  origin  Unnamed: 0                                               text  \\\n",
       "0     T2     1459086  Unconfirmed reports claiming to originate from...   \n",
       "1     T4      198836  Brexit is not the reason for the insecurity of...   \n",
       "2     T2     1131342  I’ll be on @talkRADIO in around 5-10 (3:20pm i...   \n",
       "3     T2     1345479  The judge hearing Djokovic’s deportation appea...   \n",
       "4     T2     1116059  An order to a Border Force vessel to turn back...   \n",
       "\n",
       "  author.userName misinformation stance isUSRelated notes  opinion_label  \\\n",
       "0    _HenryBolton              O      U           0   NaN              1   \n",
       "1    _HenryBolton              O      P           0   NaN              1   \n",
       "2    _HenryBolton              O      P           1   NaN              1   \n",
       "3    _HenryBolton              T      U           0   NaN              0   \n",
       "4    _HenryBolton              O      U           0   NaN              1   \n",
       "\n",
       "   true_label  claimbuster_score  \n",
       "0         NaN           0.505682  \n",
       "1         NaN           0.495295  \n",
       "2         NaN           0.418709  \n",
       "3         1.0           0.605284  \n",
       "4         NaN           0.530550  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2738.000000\n",
       "mean        0.586638\n",
       "std         0.170256\n",
       "min         0.087925\n",
       "25%         0.466782\n",
       "50%         0.606765\n",
       "75%         0.714399\n",
       "max         0.920794\n",
       "Name: claimbuster_score, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['claimbuster_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(91)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['claimbuster_score'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('claimbuster.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claim Spotting Models\n",
    "https://github.com/utaresearch/claimbuster-spotter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer\n",
    "https://colab.research.google.com/github/idirlab/claimspotter/blob/master/adv_transformer/adv_transformer-notebook.ipynb#scrollTo=V5DpLL03WJ-v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'claimspotter'...\n",
      "remote: Enumerating objects: 9856, done.\u001b[K\n",
      "remote: Counting objects: 100% (706/706), done.\u001b[K\n",
      "remote: Compressing objects: 100% (273/273), done.\u001b[K\n",
      "remote: Total 9856 (delta 485), reused 592 (delta 433), pack-reused 9150 (from 1)\u001b[K\n",
      "Receiving objects: 100% (9856/9856), 12.93 MiB | 21.08 MiB/s, done.\n",
      "Resolving deltas: 100% (6904/6904), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/idirlab/claimspotter.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/misinformation/claimspotter/adv_transformer/claimspotter/adv_transformer\n"
     ]
    }
   ],
   "source": [
    "%cd /workspaces/misinformation/claimspotter/adv_transformer/claimspotter/adv_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /home/codespace/.python/current/lib/python3.12/site-packages (75.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting absl-py==1.0.0 (from -r requirements.txt (line 1))\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting aiofiles==0.5.0 (from -r requirements.txt (line 2))\n",
      "  Using cached aiofiles-0.5.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting astroid==2.4.2 (from -r requirements.txt (line 3))\n",
      "  Using cached astroid-2.4.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.6.3)\n",
      "Collecting asyncpg==0.20.1 (from -r requirements.txt (line 5))\n",
      "  Using cached asyncpg-0.20.1.tar.gz (734 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4==4.9.1 (from -r requirements.txt (line 6))\n",
      "  Using cached beautifulsoup4-4.9.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting bert-tensorflow==1.0.1 (from -r requirements.txt (line 7))\n",
      "  Using cached bert_tensorflow-1.0.1-py2.py3-none-any.whl.metadata (530 bytes)\n",
      "Collecting blis==0.4.1 (from -r requirements.txt (line 8))\n",
      "  Using cached blis-0.4.1.tar.gz (1.8 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting boto==2.49.0 (from -r requirements.txt (line 9))\n",
      "  Using cached boto-2.49.0-py2.py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting boto3==1.14.4 (from -r requirements.txt (line 10))\n",
      "  Using cached boto3-1.14.4-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting botocore==1.17.4 (from -r requirements.txt (line 11))\n",
      "  Using cached botocore-1.17.4-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting bs4==0.0.1 (from -r requirements.txt (line 12))\n",
      "  Using cached bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cachetools==4.1.0 (from -r requirements.txt (line 13))\n",
      "  Using cached cachetools-4.1.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting catalogue==1.0.0 (from -r requirements.txt (line 14))\n",
      "  Using cached catalogue-1.0.0-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting certifi==2020.4.5.2 (from -r requirements.txt (line 15))\n",
      "  Using cached certifi-2020.4.5.2-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting chardet==3.0.4 (from -r requirements.txt (line 16))\n",
      "  Using cached chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting click==7.1.2 (from -r requirements.txt (line 17))\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting cycler==0.10.0 (from -r requirements.txt (line 18))\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl.metadata (722 bytes)\n",
      "Collecting cymem==2.0.3 (from -r requirements.txt (line 19))\n",
      "  Using cached cymem-2.0.3.tar.gz (51 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docopt==0.6.2 (from -r requirements.txt (line 20))\n",
      "  Using cached docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docutils==0.15.2 (from -r requirements.txt (line 21))\n",
      "  Using cached docutils-0.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting elasticsearch==7.7.1 (from -r requirements.txt (line 22))\n",
      "  Using cached elasticsearch-7.7.1-py2.py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting emoji==1.2.0 (from -r requirements.txt (line 23))\n",
      "  Using cached emoji-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting filelock==3.0.12 (from -r requirements.txt (line 24))\n",
      "  Using cached filelock-3.0.12-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting Flask==1.1.2 (from -r requirements.txt (line 25))\n",
      "  Using cached Flask-1.1.2-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting Flask-Cors==3.0.8 (from -r requirements.txt (line 26))\n",
      "  Using cached Flask_Cors-3.0.8-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting fuzzywuzzy==0.18.0 (from -r requirements.txt (line 27))\n",
      "  Using cached fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting gast==0.3.3 (from -r requirements.txt (line 28))\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting gensim==3.8.3 (from -r requirements.txt (line 29))\n",
      "  Using cached gensim-3.8.3.tar.gz (23.4 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gino==1.0.1 (from -r requirements.txt (line 30))\n",
      "  Using cached gino-1.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting google-auth==1.17.2 (from -r requirements.txt (line 31))\n",
      "  Using cached google_auth-1.17.2-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting google-auth-oauthlib==0.4.1 (from -r requirements.txt (line 32))\n",
      "  Using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from -r requirements.txt (line 33)) (0.2.0)\n",
      "Collecting grpcio==1.29.0 (from -r requirements.txt (line 34))\n",
      "  Using cached grpcio-1.29.0.tar.gz (19.6 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gunicorn==20.0.4 (from -r requirements.txt (line 35))\n",
      "  Using cached gunicorn-20.0.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting h11==0.9.0 (from -r requirements.txt (line 36))\n",
      "  Using cached h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting h2==3.2.0 (from -r requirements.txt (line 37))\n",
      "  Using cached h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting h5py==2.10.0 (from -r requirements.txt (line 38))\n",
      "  Using cached h5py-2.10.0.tar.gz (301 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting hpack==3.0.0 (from -r requirements.txt (line 39))\n",
      "  Using cached hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting hstspreload==2020.6.16 (from -r requirements.txt (line 40))\n",
      "  Using cached hstspreload-2020.6.16-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting httptools==0.1.1 (from -r requirements.txt (line 41))\n",
      "  Using cached httptools-0.1.1.tar.gz (106 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting httpx==0.11.1 (from -r requirements.txt (line 42))\n",
      "  Using cached httpx-0.11.1-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Collecting hyperframe==5.2.0 (from -r requirements.txt (line 43))\n",
      "  Using cached hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting idna==2.9 (from -r requirements.txt (line 44))\n",
      "  Using cached idna-2.9-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting importlib-metadata==1.6.1 (from -r requirements.txt (line 45))\n",
      "  Using cached importlib_metadata-1.6.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting inflect==4.1.0 (from -r requirements.txt (line 46))\n",
      "  Using cached inflect-4.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting isort==4.3.21 (from -r requirements.txt (line 47))\n",
      "  Using cached isort-4.3.21-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Collecting itsdangerous==1.1.0 (from -r requirements.txt (line 48))\n",
      "  Using cached itsdangerous-1.1.0-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting jaraco.itertools==5.0.0 (from -r requirements.txt (line 49))\n",
      "  Using cached jaraco.itertools-5.0.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting Jinja2==2.11.2 (from -r requirements.txt (line 50))\n",
      "  Using cached Jinja2-2.11.2-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting jmespath==0.10.0 (from -r requirements.txt (line 51))\n",
      "  Using cached jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting joblib==0.15.1 (from -r requirements.txt (line 52))\n",
      "  Using cached joblib-0.15.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting Keras==2.3.1 (from -r requirements.txt (line 53))\n",
      "  Using cached Keras-2.3.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting Keras-Applications==1.0.8 (from -r requirements.txt (line 54))\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting Keras-Preprocessing==1.1.2 (from -r requirements.txt (line 55))\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting kiwisolver==1.2.0 (from -r requirements.txt (line 56))\n",
      "  Using cached kiwisolver-1.2.0.tar.gz (52 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting lazy-object-proxy==1.4.3 (from -r requirements.txt (line 57))\n",
      "  Using cached lazy-object-proxy-1.4.3.tar.gz (34 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting Markdown==3.2.2 (from -r requirements.txt (line 58))\n",
      "  Using cached Markdown-3.2.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting MarkupSafe==1.1.1 (from -r requirements.txt (line 59))\n",
      "  Using cached MarkupSafe-1.1.1.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting mccabe==0.6.1 (from -r requirements.txt (line 60))\n",
      "  Using cached mccabe-0.6.1-py2.py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting more-itertools==8.4.0 (from -r requirements.txt (line 61))\n",
      "  Using cached more_itertools-8.4.0-py3-none-any.whl.metadata (35 kB)\n",
      "Collecting multidict==4.7.6 (from -r requirements.txt (line 62))\n",
      "  Using cached multidict-4.7.6.tar.gz (50 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting murmurhash==1.0.8 (from -r requirements.txt (line 63))\n",
      "  Using cached murmurhash-1.0.8.tar.gz (12 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting nltk==3.5 (from -r requirements.txt (line 64))\n",
      "  Using cached nltk-3.5.zip (1.4 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numpy==1.26.0 (from -r requirements.txt (line 65))\n",
      "  Using cached numpy-1.26.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "Collecting oauthlib==3.1.0 (from -r requirements.txt (line 66))\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting opt-einsum==3.2.1 (from -r requirements.txt (line 67))\n",
      "  Using cached opt_einsum-3.2.1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting packaging==20.4 (from -r requirements.txt (line 68))\n",
      "  Using cached packaging-20.4-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pandas==2.0.3 (from -r requirements.txt (line 69))\n",
      "  Using cached pandas-2.0.3.tar.gz (5.3 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting params==0.9.0 (from -r requirements.txt (line 70))\n",
      "  Using cached params-0.9.0-py3-none-any.whl.metadata (631 bytes)\n",
      "Collecting pipreqs==0.4.10 (from -r requirements.txt (line 71))\n",
      "  Downloading pipreqs-0.4.10-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting plac==1.1.3 (from -r requirements.txt (line 72))\n",
      "  Downloading plac-1.1.3-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting preshed==3.0.2 (from -r requirements.txt (line 73))\n",
      "  Downloading preshed-3.0.2.tar.gz (167 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[6 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-h8gvbpsi/preshed_052d4e23733d40978144654b1ca94516/setup.py\", line 9, in <module>\n",
      "  \u001b[31m   \u001b[0m     from distutils import ccompiler, msvccompiler\n",
      "  \u001b[31m   \u001b[0m ImportError: cannot import name 'msvccompiler' from 'distutils' (/usr/local/python/3.12.1/lib/python3.12/site-packages/setuptools/_distutils/__init__.py). Did you mean: 'ccompiler'?\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"BB\"] = \"./output/bb/\"\n",
    "os.environ[\"BBA\"] = \"./output/bba/\"\n",
    "os.environ[\"DB\"] = \"./output/db/\"\n",
    "os.environ[\"DBA\"] = \"./output/dba/\"\n",
    "os.environ[\"RB\"] = \"./output/rb/\"\n",
    "os.environ[\"RBA\"] = \"./output/rba/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/misinformation/claimspotter/adv_transformer/claimspotter\n",
      "/workspaces/misinformation/claimspotter/adv_transformer/claimspotter/adv_transformer/core/utils/transformations.py:331: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  sentence = re.sub('(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)', 'url', sentence)\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/workspaces/misinformation/claimspotter/adv_transformer/claimspotter/adv_transformer/train.py\", line 28, in <module>\n",
      "    from adv_transformer.core.utils.data_loader import DataLoader\n",
      "  File \"/workspaces/misinformation/claimspotter/adv_transformer/claimspotter/adv_transformer/core/utils/data_loader.py\", line 31, in <module>\n",
      "    from . import transformations as transf\n",
      "  File \"/workspaces/misinformation/claimspotter/adv_transformer/claimspotter/adv_transformer/core/utils/transformations.py\", line 24, in <module>\n",
      "    import spacy\n",
      "ModuleNotFoundError: No module named 'spacy'\n"
     ]
    }
   ],
   "source": [
    "%cd /workspaces/misinformation/claimspotter/adv_transformer/claimspotter\n",
    "\n",
    "!python3 -m adv_transformer.train \\\n",
    "    --cs_model_dir=$BB \\\n",
    "    --cs_adv_train=False \\\n",
    "    --cs_gpu=0 \\\n",
    "    --cs_train_steps=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Directional LSTM\n",
    "https://colab.research.google.com/github/idirlab/claimspotter/blob/master/bidirectional_lstm/bilstm-notebook.ipynb#scrollTo=9s5qGyi5jWjU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = data['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
