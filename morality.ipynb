{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.45.1)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/codespace/.python/current/lib/python3.12/site-packages (4.45.1)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/workspaces/misinformation/df_2829_manualCoding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# List of moral dimensions (foundations)\n",
    "FOUNDATIONS = [\"care\", \"fairness\", \"loyalty\", \"authority\", \"sanctity\"]\n",
    "MODEL_BASE = \"joshnguyen/mformer-\"\n",
    "\n",
    "\n",
    "# Load the tokenizer and model for the given moral dimensions\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_BASE + FOUNDATIONS[0])  # Assuming the same tokenizer can be used\n",
    "models = {foundation: AutoModelForSequenceClassification.from_pretrained(MODEL_BASE + foundation, device_map=\"auto\") for foundation in FOUNDATIONS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text, tokenizer, models):\n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    ).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Dictionary to store probabilities for each foundation\n",
    "    results = {}\n",
    "\n",
    "    for foundation in FOUNDATIONS:\n",
    "        model = models[foundation]\n",
    "        model.eval()\n",
    "\n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # Calculate class probabilities\n",
    "        probs = torch.softmax(outputs.logits, dim=1)[:, 1]  # Assuming binary classification, class 1 represents the foundation\n",
    "        results[foundation] = probs.item()  # Store as a float\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7526/1723023138.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[FOUNDATIONS] = subset_df['text'].apply(lambda x: pd.Series(classify_text(x, tokenizer, models)))\n",
      "/tmp/ipykernel_7526/1723023138.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[FOUNDATIONS] = subset_df['text'].apply(lambda x: pd.Series(classify_text(x, tokenizer, models)))\n",
      "/tmp/ipykernel_7526/1723023138.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[FOUNDATIONS] = subset_df['text'].apply(lambda x: pd.Series(classify_text(x, tokenizer, models)))\n",
      "/tmp/ipykernel_7526/1723023138.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[FOUNDATIONS] = subset_df['text'].apply(lambda x: pd.Series(classify_text(x, tokenizer, models)))\n",
      "/tmp/ipykernel_7526/1723023138.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[FOUNDATIONS] = subset_df['text'].apply(lambda x: pd.Series(classify_text(x, tokenizer, models)))\n"
     ]
    }
   ],
   "source": [
    "subset_df[FOUNDATIONS] = subset_df['text'].apply(lambda x: pd.Series(classify_text(x, tokenizer, models)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>CreatedAt</th>\n",
       "      <th>author.id</th>\n",
       "      <th>author.userName</th>\n",
       "      <th>author.followers</th>\n",
       "      <th>author.following</th>\n",
       "      <th>...</th>\n",
       "      <th>date</th>\n",
       "      <th>createdDate</th>\n",
       "      <th>misinformation</th>\n",
       "      <th>stance</th>\n",
       "      <th>isUSRelated</th>\n",
       "      <th>care</th>\n",
       "      <th>fairness</th>\n",
       "      <th>loyalty</th>\n",
       "      <th>authority</th>\n",
       "      <th>sanctity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T2</td>\n",
       "      <td>1224387</td>\n",
       "      <td>1479667332293160967</td>\n",
       "      <td>Fox News: Harris comms chief apologizes after ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Jan 08 04:12:37 +0000 2022</td>\n",
       "      <td>303850691</td>\n",
       "      <td>01splcheck</td>\n",
       "      <td>7806</td>\n",
       "      <td>6911</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-01-07 20:12:37</td>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>T</td>\n",
       "      <td>U</td>\n",
       "      <td>1</td>\n",
       "      <td>0.245578</td>\n",
       "      <td>0.802129</td>\n",
       "      <td>0.281535</td>\n",
       "      <td>0.167433</td>\n",
       "      <td>0.029560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T4</td>\n",
       "      <td>332659</td>\n",
       "      <td>1778181695575105704</td>\n",
       "      <td>@Cartel_Cal @RepRobertGarcia It seems he's in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Wed Apr 10 22:02:07 +0000 2024</td>\n",
       "      <td>303850691</td>\n",
       "      <td>01splcheck</td>\n",
       "      <td>7789</td>\n",
       "      <td>6899</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-04-10 15:02:07</td>\n",
       "      <td>2024-04-10</td>\n",
       "      <td>CF</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0.424815</td>\n",
       "      <td>0.639714</td>\n",
       "      <td>0.178733</td>\n",
       "      <td>0.587720</td>\n",
       "      <td>0.133115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>1567887</td>\n",
       "      <td>1656440842830376960</td>\n",
       "      <td>@NatlyDenise_ Ready to bring illegal immigrant...</td>\n",
       "      <td>0</td>\n",
       "      <td>Wed May 10 23:27:26 +0000 2023</td>\n",
       "      <td>303850691</td>\n",
       "      <td>01splcheck</td>\n",
       "      <td>7814</td>\n",
       "      <td>6921</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-05-10 16:27:26</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>CF</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0.146103</td>\n",
       "      <td>0.761928</td>\n",
       "      <td>0.121260</td>\n",
       "      <td>0.367018</td>\n",
       "      <td>0.308492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T2</td>\n",
       "      <td>1303080</td>\n",
       "      <td>1477882502807052290</td>\n",
       "      <td>@cassstastrophe Well, you can take comfort tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Jan 03 06:00:21 +0000 2022</td>\n",
       "      <td>303850691</td>\n",
       "      <td>01splcheck</td>\n",
       "      <td>7806</td>\n",
       "      <td>6911</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-01-02 22:00:21</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0.484881</td>\n",
       "      <td>0.741862</td>\n",
       "      <td>0.054717</td>\n",
       "      <td>0.463428</td>\n",
       "      <td>0.167075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>1578404</td>\n",
       "      <td>1656441829464870912</td>\n",
       "      <td>I see a press conference with Arizona official...</td>\n",
       "      <td>1</td>\n",
       "      <td>Wed May 10 23:31:22 +0000 2023</td>\n",
       "      <td>303850691</td>\n",
       "      <td>01splcheck</td>\n",
       "      <td>7814</td>\n",
       "      <td>6921</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-05-10 16:31:22</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>UV</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0.191054</td>\n",
       "      <td>0.355418</td>\n",
       "      <td>0.295396</td>\n",
       "      <td>0.501547</td>\n",
       "      <td>0.328975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  origin  Unnamed: 0                   id  \\\n",
       "0     T2     1224387  1479667332293160967   \n",
       "1     T4      332659  1778181695575105704   \n",
       "2     T3     1567887  1656440842830376960   \n",
       "3     T2     1303080  1477882502807052290   \n",
       "4     T3     1578404  1656441829464870912   \n",
       "\n",
       "                                                text  retweetCount  \\\n",
       "0  Fox News: Harris comms chief apologizes after ...             0   \n",
       "1  @Cartel_Cal @RepRobertGarcia It seems he's in ...             0   \n",
       "2  @NatlyDenise_ Ready to bring illegal immigrant...             0   \n",
       "3  @cassstastrophe Well, you can take comfort tha...             0   \n",
       "4  I see a press conference with Arizona official...             1   \n",
       "\n",
       "                        CreatedAt  author.id author.userName  \\\n",
       "0  Sat Jan 08 04:12:37 +0000 2022  303850691      01splcheck   \n",
       "1  Wed Apr 10 22:02:07 +0000 2024  303850691      01splcheck   \n",
       "2  Wed May 10 23:27:26 +0000 2023  303850691      01splcheck   \n",
       "3  Mon Jan 03 06:00:21 +0000 2022  303850691      01splcheck   \n",
       "4  Wed May 10 23:31:22 +0000 2023  303850691      01splcheck   \n",
       "\n",
       "   author.followers  author.following  ...                 date  createdDate  \\\n",
       "0              7806              6911  ...  2022-01-07 20:12:37   2022-01-07   \n",
       "1              7789              6899  ...  2024-04-10 15:02:07   2024-04-10   \n",
       "2              7814              6921  ...  2023-05-10 16:27:26   2023-05-10   \n",
       "3              7806              6911  ...  2022-01-02 22:00:21   2022-01-02   \n",
       "4              7814              6921  ...  2023-05-10 16:31:22   2023-05-10   \n",
       "\n",
       "  misinformation stance isUSRelated      care  fairness   loyalty  authority  \\\n",
       "0              T      U           1  0.245578  0.802129  0.281535   0.167433   \n",
       "1             CF      A           1  0.424815  0.639714  0.178733   0.587720   \n",
       "2             CF      A           1  0.146103  0.761928  0.121260   0.367018   \n",
       "3              E      A           1  0.484881  0.741862  0.054717   0.463428   \n",
       "4             UV      A           1  0.191054  0.355418  0.295396   0.501547   \n",
       "\n",
       "   sanctity  \n",
       "0  0.029560  \n",
       "1  0.133115  \n",
       "2  0.308492  \n",
       "3  0.167075  \n",
       "4  0.328975  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
